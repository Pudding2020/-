# 第一章

- 用户角度上，操作系统是一个控制软件：管理应用程序、为应用程序程序提供服务、杀死应用程序
    
    资源管理：管理外设、分配资源
    
             CPU——进程（CPU虚拟化为进程）  磁盘——文件  内存——地址空间
             
    承上启下作用：硬件之上 应用程序之下
    
    研究kernel（内核），而不是shell（外壳）（如：图形界面、字符命令行）
    
- 操作系统内部组件——Kernel

    1、CPU管理（CPU调度、进线程管理）
    
    2、内存管理（物理内存、虚拟内存）
    
    3、文件系统管理
    
    4、中断处理与设备驱动（需要良好的硬件管理和合理的资源分配）
    
- OS Kernel的特征

    1、并发 计算机系统中同时存在多个运行的程序，需要OS管理和调度
       
       （一个段时间内多个程序运行；并行：在一个时间点上多个程序可以同时运行，要求有多个CPU）
       
    2、共享 互斥共享、“同时”访问
    
    3、虚拟 利用多道程序设计技术，让每个用户都觉得有一个计算机专门为他服务
    
    4、异步
    
       程序的执行不是一贯到底，而是走走停停，向前推进的速度不可预知
       
       但只要运行环境相同，OS需保证程序运行的结果也要相同
    
- 操作系统的结构

    1、简单操作系统MS-DOS：1981-1994 汇编语言 不分模块的单体内核
    
    2、Unix：1972年由Kenneth Thompson和Dennid Ritchie在贝尔实验室设计  C语言
    
    3、微内核的设计：尽可能把内核功能移到用户空间
    
    4、一种极端的架构：外核
    
    5、VMM虚拟机监视器：将单独的机器接口转换成很多幻象，每个接口是一个原是计算机的有效副本，并完成所有处理器命令
    
      操作系统之下为VMM，VMM之下为硬件
      
      多操作系统共享硬件资源
      

# 第二章  启动、中断、异常和系统调用

## 启动

一、启动过程

    1、DISK（硬盘）：存放OS    
    
       BIOS（基本I/O处理系统）：让计算机开机后可以检测各种外设  
       
       Bootloader：放在硬盘的第一个主引导扇区 加载OS，让OS从硬盘放入内存，使CPU可以执行OS
       
    2、上电后：
    
       （1）BIOS从特定地址开始执行，进行初始化检查（如：POST（加电自检）、寻找显卡和执行BIOS）
       
            若一切正常，则加载Bootloader，从硬盘放入内存中。
    
            BIOS在内存中占特定地址，以X86为例，地址为CS:IP=0xf000:fff0，CS-段寄存器，IP指令寄存器
           
       （2）Bootloader掌握CPU控制权，将OS从硬盘上加载内存中。    
       
            Boothloader的位置由BIOS设定，占512字节
            
       （3）OS掌握CPU控制权，从OS起始位置开始执行
       
二、操作系统与设备和程序交互（开启后正常工作）

## 系统调用、异常、中断

一、定义

    系统调用（来源于应用程序）：应用程序主动向操作系统发出服务请求；

    异常（来源于不良应用程序）：非法指令或其他坏的处理状态，如：内存出错
    
    中断（来源于外设）：来自不同的硬件设备的计时器和网络的中断
    
二、操作系统存在的意义

    在计算机运行中，内核是被信任的第三方，而应用程序不被信任，不可直接访问外设；
    
    只有内核可以执行特权指令；
    
    为了方便应用程序。
    
三、三者的异同

    1、源头
    
        中断：外设
        
        异常：应用程序意想不到的行为
        
        系统调用：应用程序请求操作提供服务（主动、有意识的，如读取文件，发送文件等）
   
    2、处理时间
   
        中断：异步（不知什么时候会产生）
        
        异常：同步（知道执行这条指令后会产生）
        
        系统调用：异步或同步（发出请求是同步的，执行完成返回时可能为同步也可能为异步）
        
    3、响应
        
        中断：持续，对用户应用程序是透明的（应用程序不知道什么时候产生中断）
        
        异常：杀死或重新执行意想不到的应用程序指令
        
        系统调用：等待和持续
       
四、中断和异常处理机制

![](https://i.bmp.ovh/imgs/2020/04/5ca03bd05d40b7a5.png)

    1、首先，都需要知道异常服务例程发生了哪种中断或异常，由中断向量表获得它们的编号及对应的地址，直接转跳
        
        软硬件都有操作
        
    2、中断
    
        硬件：设置中断标记（CPU初始化）
        
              （1）将内部、外部事件设置中断标记；
              
              （2）中断事件的ID。
              
         软件：保存当前处理状态；中断服务程序处理；清除中断标记；恢复之前保存的处理状态。
         
     3、异常
     
         同样有异常编号
        
         保存现场；异常处理（杀死产生了异常的程序；重新执行异常指令）；恢复现场。
         
五、系统调用

    1、程序访问主要是通过高层次的API接口，而不是直接进行系统调用
    
        -- Win32 API 用于 Windows
        
        -- POSIX（通用、可移植的） API 用于 POSIX-based systems （包括UNIX 、LINUX 、MAC OS X 的所有版本）
        
        -- Java API 用于 JAVA 虚拟机（JVM）
        
    2、特权级转换的变化
    
        用户态：应用程序在执行过程中，CPU所处的特权级状态（特权级很低，不能直接访问某些特殊机械指令和IO）
    
        内核态：操作系统运行时，COU所处的状态，可以完全控制整个计算机系统
        
        应用程序调用系统调用时，完成从用户态到内核态转换，控制权从应用程序交到操作系统。
        
        操作系统对应用程序发出的参数、ID号等作出标识，使其对系统调用进行识别，完成具体服务
         
    3、其他变化
    
        函数调用：在一个栈空间完成参数传递和返回
        
        系统调用：应用程序和OS有各自的堆栈
        
        需完成堆栈的切换  所以开销比函数调用大  但是安全、可靠
        
    4、小结：跨越操作系统边界的开销
    
        （1）执行时间上的开销超过程序调用
        
        （2）开销
        
            -- 建立中断、异常、系统调用号与对应服务，例程映射关系的初始化开销；
            
            -- 建立内核堆栈；
            
            -- 验证参数（不信任应用程序，对其进行检查）；
            
            -- 内核态映射到用户态的地址空间，更新页面映射权限；
            
            -- 内核态独立地址空间（TLB）
            
            这些开销值得 使系统安全稳定地运行
            

# 第三章  操作系统对物理内存的管理（一）

## 计算机体系结构及内存分层体系

一、 计算机体系结构

    1、三部分
    
        -- CPU：完成程序软件的执行和控制
        
        -- 内存：放置程序代码及它所处理的数据
        
        -- 设备：配合程序完成功能
        
二、内存分层体系：CPU所访问的数据、指令在内存中的位置

![](https://i.bmp.ovh/imgs/2020/04/d25aac9ef74d8c18.png)

    寄存器、cache（高速缓存） 位于 CPU 内部，OS无法直接管理；速度快；容量小；
    
    主存/物理内存：放置OS本身要运行的代码；速度慢一些；容量大；掉电丢失数据；
        
    硬盘/虚拟内存：速度慢；容量大；
    
三、OS 在内存管理中需要完成的目标
    
    抽象（逻辑地址空间）、保护（独立地址空间）、共享（访问相同内存）、虚拟化（更多的地址空间，放置暂时不执行的应用程序）
    
四、在 OS 中管理内存的不同方法

    程序重定位；分段；分页；虚拟内存；按需分页虚拟内存
    
五、OS 为一个特殊的软件，实现高度依赖于硬件

    必须知道内存架构；
    
    MMU（内存管理单元）：硬件组件负责处理 CPU 的内存访问请求
    
## 地址空间与地址生成

一、 地址空间

    物理地址空间（PA）：硬件支持的地址空间；与硬件直接对应，如：内存条代表的主存、硬盘；由硬件完成管理和控制；
    
    逻辑地址空间(LA)：一个运行的程序所拥有的内存范围，是一个一维的线性空间；如 C 中变量名、函数名

二、地址生成

    1、 逻辑地址生成：编译-- 汇编-- 链接-- 载入（程序重定位，放入内存中，此时仍为逻辑地址）；会有偏移，偏移量可以为0；
    
                    过程中不需要 OS 参与；

    2、 物理地址：CPU将指令从内存中取出，得到逻辑地址；
    
             CPU中的 MMU 完成逻辑地址到物理地址的映射；
             
             硬件从相应物理内存中取出地址。
             
![](https://i.bmp.ovh/imgs/2020/04/d8965bd3944b9710.png)
             
    3、 物理地址生成的整体流程：
    
        -- CPU
        
            ALU 计算逻辑单元：需要逻辑地址的内存内容，发出请求，发出逻辑地址；
            
            MMU 内存管理单元：进行逻辑地址和物理地址的转换（查找映射表中有无对应的物理地址，没有的话，则去内存中 MAP 找）；
            
            CPU 控制逻辑：给总线发送物理地址请求；
            
        -- 内存
        
            发送物理地址的内容给 CPU ；或接收 CPU 数据到物理地址；
            
        -- 操作系统
        
            （在以上四步之前）建立逻辑地址LA和物理地址PA 的映射；可以放在内存中，由CPU缓存，加快访问过程
    
三、地址安全检查

![](https://i.bmp.ovh/imgs/2020/04/7673b93054adfe7b.png)

## 连续物理内存分配：内存碎片与分区的动态分配

一、内存碎片问题：空闲内存不能被利用

    外部碎片：在分配单元间的未使用内存；
    
    内部碎片：在分配单元中的未使用内存（已经分配给了应用程序，但它未使用）；
    
二、分区的动态分配

    1、简单的内存管理方法
    
        当一个程序准许运行在内存中时，分配一个连续的区间；
        
        分配一个连续的内存空间给运行的程序以访问数据；
        
    2、分配策略
    
        首次适配；最优适配；最差适配；

    3、首次适配（first fit）
    
        简单实现：为了分配 n 字节，使用第一个可用空闲块以致块的尺寸比 n 大；
        
        需求：- 按地址排序的空闲块列表；
        
              - 分配需要寻找一个合适的分区；
              
              - 重分配（若有）需要检查，看是否自由分区能合并于相邻的空闲分区；
              
        优势：- 简单；
        
              - 易于产生更大空闲块，向着地址空间的结尾；
              
        劣势： - 容易产生外部碎片；
        
               - 不确定性；
        
    4、最优适配（best fit）
    
        为了分配 n 字节，使用最小的可用空闲块，以致块的尺寸比 n 大；
        
        需求：- 按尺寸排序的空闲块列表；
        
              - 分配需要寻找一个合适的分区；
              
              - 重分配（若有）需要检查，看是否自由分区能合并于相邻的空闲分区；
              
        优势：- 避免分割大空闲块，当大部分分配是小尺寸时非常有效；
        
              - 最小化外部碎片产生的尺寸；
              
              - 比较简单；
    
        劣势：- 易产生外部碎片；
        
              - 重分配慢；
              
              - 易产生很多没用的微小碎片，不利于后续分配和管理；
              
     5、最差适配（worst fir）
     
        为了分配 n 字节，使用最大可用空闲块，以致块的尺寸比 n 大；
        
        需求：- 按尺寸排序的空闲块列表；
        
              - 分配很快（获得最大的分区）；
              
              - 重分配（若有）需要检查，看是否自由分区能合并于相邻的空闲分区；
              
         优势：避免有太多微小的碎片，分配中等尺寸效果最好；
         
         劣势：- 重分配慢；
         
               - 易产生外部碎片；
               
               - 易于破碎大的空闲块以致大分区无法被分配；
               
    小结：以上为简单管理算法，没有最好和最坏，因为程序需要的内存是随机的，可能大可能小。
     
## 连续物理内存分配：压缩式与交换式碎片整理

    压缩式compress：重置程序，合并空闲块（要求所有程序是动态可重置的）（何时重置？开销如何？）

    交换式swap：运行程序需要更多的内存时，抢占等待的程序，将等待程序copy到磁盘，回收他们的内存


# 第四章 操作系统对物理内存的管理（二）

## 非连续内存分配：分段（Segmentation）

一、使用非连续分配的原因

    1、连续内存分配的缺点：
    
        分配给一个程序的物理内存是连续的；
        
        内存利用率较低；
        
        有外碎片、内碎片的问题；
        
    2、非连续分配的优点：
    
        一个程序的物理地址空间是非连续的；
        
        更好的内存利用和管理；
        
        允许共享代码与数据（共享库等...）；
        
        支持动态加载和动态链接；
        
        缺点：管理开销大
        
        如何建立虚拟地址和物理地址之间的转换？可使用软件方案和硬件方案，软件方案开销可能很大，所以使用硬件
        
        两种硬件方案：分段、分页
        
二、分段 —— 更好地分离和共享

    进程的段地址空间由多个段组成：主代码段、子模块代码段、公用库代码段、堆栈段、堆数据、初始化数据段、符号表等

    将一个连续逻辑地址的应用程序（大的一维字节流，一段）  通过分段技术支持 映射为不连续的物理地址（多段）
        
三、分段寻址方案

    1、段访问机制
    
    - 一个段：一个内存块，一个逻辑地址空间
    
    - 程序访问内存地址需要：一个二维的二元组（s，addr；s —— 段号segnment；addr —— 段内偏移）

    - 有两种实现方式
    
        段寄存器 + 地址寄存器（s，addr分开存放，如x86）；
        
        单地址：（s，addr挨着存放）；
    
    2、段访问的硬件实现
    
![](https://i.bmp.ovh/imgs/2020/04/88b73b95ba7ae46a.png)

    （1）CPU执行应用程序的每条指令，通过段号寻找所在段的起始物理地址，映射关系在段表中储存；
    
            段表：由 OS （在寻址前）建立
            
                  - 存储段的起始地址（逻辑地址段号与物理地址段号的对应关系）；
            
                  - 存储段的长度限制；
                  
                  Index - 段号
                  
     （2）CPU通过段表信息，检查段长度是否满足长度限制，若满足，则合法，将起始地址+偏移量形成物理地址，取出数据交给CPU处理；
     
            若不满足，则为非法机制，CPU对OS产生异常。

    

## 非连续内存分配：分页（Paging）（大部分 CPU 采取的方式）

一、分页地址空间

    同样需要页号和页偏移；但段的大小可变，页帧/页大小不可变
    
    1、划分物理内存至固定大小的帧（frame）：大小是2的幂，eg：512,4096,8192；
    
        划分逻辑地址空间至相同大小的页（page）：大小是2的幂，eg：512,4096,8192
        
    2、建立方案：转换逻辑地址为物理地址（pages to frames）
    
        页表；
        
        MMU/TLB（快表，完成对页表的缓存）；
        
    3、帧：物理内存被分割为大小相等的帧
    
        一个内存物理地址是一个二元组（f，o）  物理地址 = 2^S X f + o
             
        f —— 帧号（F位，共有2^F个帧）  o —— 帧内偏移（S位，每帧有2^S字节）
        
        eg：16-bit的地址空间，9-bit（512 byte）大小的页帧，物理地址=（3,6），物理地址=1542
        
            F=7(16-9) S=9  f=3  o=6  物理地址 = 2^9*3+6 = 1536+6 = 1542
            
     4、页：一个程序的逻辑地址空间被划分为大小相等的页
     
        页内偏移的大小 = 帧内偏移的大小    页号大小 < / > 帧号大小
        
        一个逻辑地址是一个二元组（p,o）  虚拟地址 = 2^S X p + o
        
        p —— 页号（P位，2^P个页）  o —— 页内偏移（S位，每页有2^S字节）

二、页寻址机制 —— 页映射到帧

    1、程序的逻辑地址由很多页组成，每一页大小相同
    
        逻辑地址中的页号是连续的；物理地址中的帧号是不连续的；不是所有的页都有对应的帧
        
        页是连续的虚拟内存；帧是非连续的物理内存；有助于减少碎片
    
    2、实现过程
    
![](https://i.bmp.ovh/imgs/2020/04/258fe46dbe579727.png)
    
        （1）CPU 将页号作为索引，结合页表基址（PTBR - 页表基址寄存器），找到页表的存放位置，查询页表（一个大数组）
        
            若存在位为0，表示不存在此页号对应的帧号，异常；
            
            若存在位为1，表示存在，得到f（帧号）；
        
        （2）f 与 o 得到物理地址
        
        （OS 在之前建立页表）

## 非连续内存分配：页表（Page Table）

一、页表概述

    1、页表结构
    
        - 每个运行的程序都有一个页表，属于程序运行状态，会动态变化
        
        - 页表项组成：（1）帧号f
        
                     （2）页表项标志：存在位（resident bit）；修改位（dirty bit）；引用位（clock/reference bit）
        
        eg：16位地址的系统（64KB，2^10^6）,32KB的物理内存，每页1024byte（偏移）
        
    2、分页机制的性能问题
    
        访问一个内存单元需要2次内存访问：一次用于获取页表项；一次用于访问数据
        
        （1）由于逻辑地址空间很大，导致页表可能非常大，eg：64位机器如果每页1024字节，一个页表的大小：2^64/2^10 = 2^54  
        
        （2）由于不同的应用程序需要不同的页表，n个则需要n份页表；
        
        （3）效率问题：CPU空间小，放不下页表，需将其放入内存，所以访问2次内存。
        
    3、如何解决？
    
        （1）缓存：常用数据或内容放入CPU中，提升访问速度；
        
        （2）间接访问
        

二、转换后备缓冲区（Translation Look-aside Buffer，TLB）—— 从速度上解决

    CPU 的 MMU 中
    
    缓存近期访问的页帧转换表项
    
    TLB使用associative memory（关联内存）实现，具备快速访问性能（速度快，时间代价大，所以容量小）；
    
    如果TLB命中，物理页号可以很快被获取；如果TLB未命中，则查页表，对应的表项被更新到TLB中。
    
    TLB未命中（缺失）的概率不会很大，一个32位系统有4K页表，访问4K次才会导致TLB缺失；写程序时尽量占用局部空间，减少缺失。
    
    TLB缺失后，从页表中取出再存到CPU中TLB的过程：-X86：由硬件完成；其它CPU：由os(软件)完成。

三、二级/多级 页表—— 从空间上解决（时间换空间）

    1、二级页表：将页号分为两个小的页号P1、P2，偏移地址不变，将对大页表的寻址分为对两个小页表的寻址
    
            CPU由P1及一级页表的起始地址查询一级页表，得到二级页表的起始地址；由P2及二级页表的起始地址得到帧号。
            
            优点：节省空间，若对应页号的表项不存在，则在二级页表中不需要存在
            
    2、多级页表：通过把页号分为k个部分，来实现多级间接页表，建立页表“树”

四、反向页表

    1、以上方法（前向映射）：页表大小与逻辑地址空间对应（以逻辑页页号作为index索引，来查找页号），逻辑地址空间越大，则页表越大
    
        反向映射：将物理地址的物理页号（页帧号）为索引，映射为逻辑地址的逻辑页号
        
                让页表与物理地址空间的大小相对应（逻辑/虚拟地址空间增长速度快于物理地址空间）
                
     2、基于页寄存器的方案
     
        （1）页寄存器中存放：帧号为索引，页号为值的数组
        
        （2）每个帧和一个寄存器关联，寄存器内容包括：存在位（residence bit）--此帧是否被占用、
        
            occupier--对应的页号P、保护位（protection bit）
            
            eg：物理内存大小 4096*4096=4K*4KB=16MB     页面大小4096bytes=4KB   页帧数4096=4K
            
                页寄存器使用的空间（假设8 bytes/register）8*4096=32 Kbytes
                
                页寄存器带来的额外开销32K/16M=0.2%（大约）———— 转换表的大小跟逻辑地址空间的大小无关
                
                虚拟内存的大小：任意
                
      3、基于关联内存的方案
      
        如果帧数较少，页寄存器可以被放置在关联内存中
        
        在关联内存中查找逻辑页号：成功--帧号被提取；失败--页错误异常（page fault）
        
        限制因素：大量的关联内存非常昂贵，难以在单个时钟周期内完成，耗电
        
      4、基于哈希（hash）查找的方案
      
        （1）在反向页表中通过哈希算法来搜索一个页对应的帧号
        
            对页号做哈希计算，为了在“帧表”（每帧拥有一个表项）中获取对应的帧号
            
            页i被放置在表中f（i）位置，其中f是设定的哈希函数
            
        （2）为了查找页i，执行下列操作：
        
            计算哈希函数f（i），并且使用它作为页寄存器表的索引；
            
            获取对应的页寄存器；
            
            检查寄存器标签是否包含i，如果包含，则代表成功，否则失败。
      
        （3）帧号和页号的对应关系由哈希函数实现（可硬件，可软件，为了速度快，用硬件）
        
            将哈希函数加上当前运行程序的ID，可提高查找速度

# 第五章  虚拟内存（一）

## 虚拟内存的起因

一、程序规模增长远快于存储器容量增长速度

    理想中的存储器：更大、更快、更便宜的非易失性存储器
    
    实际中的存储器：
    
![](https://i.bmp.ovh/imgs/2020/04/d7927a1c95a0e3b2.png)

    OS支持的存储器：更大、更快、更便宜好用的易失性存储器
    
二、在计算机系统中，尤其是在多道程序运行的环境下，可能会出现内存不够用的情况

    1、如果是是程序太大，超过了内存的容量，可以采用手动的覆盖（overlay）技术，只把需要的指令和数据保存在内存中；
    
    2、如果程序太多，超过了内存的容量，可采用自动交换（swapping）技术，把暂时不能执行的程序送到外存中；
    
    3、如果想要在有限容量的内存中，以更小的页粒度为单位装入更多更大的程序，可采用自动虚拟存储技术、
        
## 覆盖技术（产生于20世纪80年代、90年代初）

一、目标

    在较小的可用内存中运行较大的程序，常用于多道程序系统，与分区存储管理配合使用

二、原理

    依据程序自身逻辑结构，将程序划分为若干功能相对独立的模块；将不会同时执行的模块共享同一块内存区域，按时间先后运行（分时）。
    
    必要部分（常用功能）的代码和数据常驻内存；
    
    可选部分（不常用功能）放在其他程序模块中，平时存放在外存中，只在需要用到时装入内存；
    
    不存在调用关系的模块不必同时装入到内存，可相互覆盖，共用同一块内存区域。
    
![](https://i.bmp.ovh/imgs/2020/04/ef208b0ccd567bff.png)
    
    注：（1）调用时，放入覆盖区，B/C、D/E/F不会同时占用覆盖区
    
        （2）不会有相互调用关系的，可以放在一个覆盖区
        
三、缺点

    1、增加编程困难：
    
        需程序员划分功能模块，并确定模块间的覆盖关系，费时费力；
        
        增加了编程的复杂度；
        
    2、增加执行时间：
     
        从外存装入覆盖模块；
        
        时间换空间。
        
    eg：Turbo Pascal的Overlay系统单元支持程序员控制的覆盖技术

## 交换技术

一、目标

    多道程序在内存中时，增加正在运行或需要运行的程序的内存
    
二、实现方法

    （1）可将暂时不能运行的程序放到外存，从而获得空闲内存空间
    
    （2）OS把一个进程的整个地址空间的内容保存到外存中，而将外存中的某个进程的地址空间读入到内存中
    
        换入换出的基本单位/粒度：整个进程的地址空间
    
        换出（swap out）：把一个进程的整个地址空间保存到外存
    
        换入（swap in）：将外存中某进程的地址空间读入到内存
        
![](https://i.bmp.ovh/imgs/2020/04/44b4d83997625858.png)

三、面临的问题

    1、交换时机：何时需要发生交换？
    
        只当内存空间不够或有不够的可能时换出，尽量减少次数
    
    2、交换区大小
    
        必须足够大以存放所有用户进程的所有诶村映像的拷贝，必须能对这些内存映像进行直接存取
        
    3、程序换入时的重定位：换出后再换入时要放在原处吗？
    
        采用动态地址映射的方法

四、对程序员透明，由OS直接进行，程序员不需要知道具体细节

五、覆盖与交换的比较

    覆盖：--只能发生在没有调用关系的模块间（在一个程序里）；
    
          --程序员须给出模块间的逻辑覆盖结构；
          
          --发生在运行程序的内部模块间；
          
    交换：--以进程为单位；
    
          --不需要模块间的逻辑覆盖结构；
          
          --发生在内存程序之间（发生在内存中程序与管理程序/os之间）。
          
六、缺点

    粒度大，以进程作为交换的单位，需要把进程的整个地址空间都换进换出，增加了处理器的开销
  
## 虚存技术（虚拟内存管理技术）

一、目标

    1、只把部分程序放到内存中，从而运行比物理内存大的程序
    
        由操作系统自动完成，无需程序员的干涉；
    
    2、实现进程在内存与外存之间的交换，从而获得更多的空闲内存空间
    
        在内存和外存之间只交换进程的部分内容。

二、程序局部性原理（principle of locality）

    1、定义：程序在执行过程中的一个较短时期，所执行的指令地址和指令的操作数地址，分别局限于一定区域。
    
    2、时间局部性：一条指令的一次执行和下次执行，一个数据的一次访问和下次访问都集中在一个较短时期内
    
        空间局部性：当前指令和邻近的几条指令，当前访问的数据和邻近的几个数据都集中在一个较小区域内

        分支局部性：一条跳转指令的两次执行，很可能跳到相同的内存位置
        
    3、局部性原理的意义
    
        从理论上来说，虚拟存储技术是能够实现的，而且可取得满意的效果
        
![](https://i.bmp.ovh/imgs/2020/04/864640b99579e7b7.png)

![](https://i.bmp.ovh/imgs/2020/04/e58bc4319cb6738b.png)



三、基本概念

四、基本特征

五、虚拟页式内存管理
      
        
    
        



        
        
    
    


    

        

           
           
       

   


