# 第一章

- 用户角度上，操作系统是一个控制软件：管理应用程序、为应用程序程序提供服务、杀死应用程序
    
    资源管理：管理外设、分配资源
    
             CPU——进程（CPU虚拟化为进程）  磁盘——文件  内存——地址空间
             
    承上启下作用：硬件之上 应用程序之下
    
    研究kernel（内核），而不是shell（外壳）（如：图形界面、字符命令行）
    
- 操作系统内部组件——Kernel

    1、CPU管理（CPU调度、进线程管理）
    
    2、内存管理（物理内存、虚拟内存）
    
    3、文件系统管理
    
    4、中断处理与设备驱动（需要良好的硬件管理和合理的资源分配）
    
- OS Kernel的特征

    1、并发 计算机系统中同时存在多个运行的程序，需要OS管理和调度
       
       （一个段时间内多个程序运行；并行：在一个时间点上多个程序可以同时运行，要求有多个CPU）
       
    2、共享 互斥共享、“同时”访问
    
    3、虚拟 利用多道程序设计技术，让每个用户都觉得有一个计算机专门为他服务
    
    4、异步
    
       程序的执行不是一贯到底，而是走走停停，向前推进的速度不可预知
       
       但只要运行环境相同，OS需保证程序运行的结果也要相同
    
- 操作系统的结构

    1、简单操作系统MS-DOS：1981-1994 汇编语言 不分模块的单体内核
    
    2、Unix：1972年由Kenneth Thompson和Dennid Ritchie在贝尔实验室设计  C语言
    
    3、微内核的设计：尽可能把内核功能移到用户空间
    
    4、一种极端的架构：外核
    
    5、VMM虚拟机监视器：将单独的机器接口转换成很多幻象，每个接口是一个原是计算机的有效副本，并完成所有处理器命令
    
      操作系统之下为VMM，VMM之下为硬件
      
      多操作系统共享硬件资源
      

# 第二章  启动、中断、异常和系统调用

## 启动

一、启动过程

    1、DISK（硬盘）：存放OS    
    
       BIOS（基本I/O处理系统）：让计算机开机后可以检测各种外设  
       
       Bootloader：放在硬盘的第一个主引导扇区 加载OS，让OS从硬盘放入内存，使CPU可以执行OS
       
    2、上电后：
    
       （1）BIOS从特定地址开始执行，进行初始化检查（如：POST（加电自检）、寻找显卡和执行BIOS）
       
            若一切正常，则加载Bootloader，从硬盘放入内存中。
    
            BIOS在内存中占特定地址，以X86为例，地址为CS:IP=0xf000:fff0，CS-段寄存器，IP指令寄存器
           
       （2）Bootloader掌握CPU控制权，将OS从硬盘上加载内存中。    
       
            Boothloader的位置由BIOS设定，占512字节
            
       （3）OS掌握CPU控制权，从OS起始位置开始执行
       
二、操作系统与设备和程序交互（开启后正常工作）

## 系统调用、异常、中断

一、定义

    系统调用（来源于应用程序）：应用程序主动向操作系统发出服务请求；

    异常（来源于不良应用程序）：非法指令或其他坏的处理状态，如：内存出错
    
    中断（来源于外设）：来自不同的硬件设备的计时器和网络的中断
    
二、操作系统存在的意义

    在计算机运行中，内核是被信任的第三方，而应用程序不被信任，不可直接访问外设；
    
    只有内核可以执行特权指令；
    
    为了方便应用程序。
    
三、三者的异同

    1、源头
    
        中断：外设
        
        异常：应用程序意想不到的行为
        
        系统调用：应用程序请求操作提供服务（主动、有意识的，如读取文件，发送文件等）
   
    2、处理时间
   
        中断：异步（不知什么时候会产生）
        
        异常：同步（知道执行这条指令后会产生）
        
        系统调用：异步或同步（发出请求是同步的，执行完成返回时可能为同步也可能为异步）
        
    3、响应
        
        中断：持续，对用户应用程序是透明的（应用程序不知道什么时候产生中断）
        
        异常：杀死或重新执行意想不到的应用程序指令
        
        系统调用：等待和持续
       
四、中断和异常处理机制

![](https://i.bmp.ovh/imgs/2020/04/5ca03bd05d40b7a5.png)

    1、首先，都需要知道异常服务例程发生了哪种中断或异常，由中断向量表获得它们的编号及对应的地址，直接转跳
        
        软硬件都有操作
        
    2、中断
    
        硬件：设置中断标记（CPU初始化）
        
              （1）将内部、外部事件设置中断标记；
              
              （2）中断事件的ID。
              
         软件：保存当前处理状态；中断服务程序处理；清除中断标记；恢复之前保存的处理状态。
         
     3、异常
     
         同样有异常编号
        
         保存现场；异常处理（杀死产生了异常的程序；重新执行异常指令）；恢复现场。
         
五、系统调用

    1、程序访问主要是通过高层次的API接口，而不是直接进行系统调用
    
        -- Win32 API 用于 Windows
        
        -- POSIX（通用、可移植的） API 用于 POSIX-based systems （包括UNIX 、LINUX 、MAC OS X 的所有版本）
        
        -- Java API 用于 JAVA 虚拟机（JVM）
        
    2、特权级转换的变化
    
        用户态：应用程序在执行过程中，CPU所处的特权级状态（特权级很低，不能直接访问某些特殊机械指令和IO）
    
        内核态：操作系统运行时，COU所处的状态，可以完全控制整个计算机系统
        
        应用程序调用系统调用时，完成从用户态到内核态转换，控制权从应用程序交到操作系统。
        
        操作系统对应用程序发出的参数、ID号等作出标识，使其对系统调用进行识别，完成具体服务
         
    3、其他变化
    
        函数调用：在一个栈空间完成参数传递和返回
        
        系统调用：应用程序和OS有各自的堆栈
        
        需完成堆栈的切换  所以开销比函数调用大  但是安全、可靠
        
    4、小结：跨越操作系统边界的开销
    
        （1）执行时间上的开销超过程序调用
        
        （2）开销
        
            -- 建立中断、异常、系统调用号与对应服务，例程映射关系的初始化开销；
            
            -- 建立内核堆栈；
            
            -- 验证参数（不信任应用程序，对其进行检查）；
            
            -- 内核态映射到用户态的地址空间，更新页面映射权限；
            
            -- 内核态独立地址空间（TLB）
            
            这些开销值得 使系统安全稳定地运行
            

# 第三章  操作系统对物理内存的管理（一）

## 计算机体系结构及内存分层体系

一、 计算机体系结构

    1、三部分
    
        -- CPU：完成程序软件的执行和控制
        
        -- 内存：放置程序代码及它所处理的数据
        
        -- 设备：配合程序完成功能
        
二、内存分层体系：CPU所访问的数据、指令在内存中的位置

![](https://i.bmp.ovh/imgs/2020/04/d25aac9ef74d8c18.png)

    寄存器、cache（高速缓存） 位于 CPU 内部，OS无法直接管理；速度快；容量小；
    
    主存/物理内存：放置OS本身要运行的代码；速度慢一些；容量大；掉电丢失数据；
        
    硬盘/虚拟内存：速度慢；容量大；
    
三、OS 在内存管理中需要完成的目标
    
    抽象（逻辑地址空间）、保护（独立地址空间）、共享（访问相同内存）、虚拟化（更多的地址空间，放置暂时不执行的应用程序）
    
四、在 OS 中管理内存的不同方法

    程序重定位；分段；分页；虚拟内存；按需分页虚拟内存
    
五、OS 为一个特殊的软件，实现高度依赖于硬件

    必须知道内存架构；
    
    MMU（内存管理单元）：硬件组件负责处理 CPU 的内存访问请求
    
## 地址空间与地址生成

一、 地址空间

    物理地址空间（PA）：硬件支持的地址空间；与硬件直接对应，如：内存条代表的主存、硬盘；由硬件完成管理和控制；
    
    逻辑地址空间(LA)：一个运行的程序所拥有的内存范围，是一个一维的线性空间；如 C 中变量名、函数名

二、地址生成

    1、 逻辑地址生成：编译-- 汇编-- 链接-- 载入（程序重定位，放入内存中，此时仍为逻辑地址）；会有偏移，偏移量可以为0；
    
                    过程中不需要 OS 参与；

    2、 物理地址：CPU将指令从内存中取出，得到逻辑地址；
    
             CPU中的 MMU 完成逻辑地址到物理地址的映射；
             
             硬件从相应物理内存中取出地址。
             
![](https://i.bmp.ovh/imgs/2020/04/d8965bd3944b9710.png)
             
    3、 物理地址生成的整体流程：
    
        -- CPU
        
            ALU 计算逻辑单元：需要逻辑地址的内存内容，发出请求，发出逻辑地址；
            
            MMU 内存管理单元：进行逻辑地址和物理地址的转换（查找映射表中有无对应的物理地址，没有的话，则去内存中 MAP 找）；
            
            CPU 控制逻辑：给总线发送物理地址请求；
            
        -- 内存
        
            发送物理地址的内容给 CPU ；或接收 CPU 数据到物理地址；
            
        -- 操作系统
        
            （在以上四步之前）建立逻辑地址LA和物理地址PA 的映射；可以放在内存中，由CPU缓存，加快访问过程
    
三、地址安全检查

![](https://i.bmp.ovh/imgs/2020/04/7673b93054adfe7b.png)

## 连续物理内存分配：内存碎片与分区的动态分配

一、内存碎片问题：空闲内存不能被利用

    外部碎片：在分配单元间的未使用内存；
    
    内部碎片：在分配单元中的未使用内存（已经分配给了应用程序，但它未使用）；
    
二、分区的动态分配

    1、简单的内存管理方法
    
        当一个程序准许运行在内存中时，分配一个连续的区间；
        
        分配一个连续的内存空间给运行的程序以访问数据；
        
    2、分配策略
    
        首次适配；最优适配；最差适配；

    3、首次适配（first fit）
    
        简单实现：为了分配 n 字节，使用第一个可用空闲块以致块的尺寸比 n 大；
        
        需求：- 按地址排序的空闲块列表；
        
              - 分配需要寻找一个合适的分区；
              
              - 重分配（若有）需要检查，看是否自由分区能合并于相邻的空闲分区；
              
        优势：- 简单；
        
              - 易于产生更大空闲块，向着地址空间的结尾；
              
        劣势： - 容易产生外部碎片；
        
               - 不确定性；
        
    4、最优适配（best fit）
    
        为了分配 n 字节，使用最小的可用空闲块，以致块的尺寸比 n 大；
        
        需求：- 按尺寸排序的空闲块列表；
        
              - 分配需要寻找一个合适的分区；
              
              - 重分配（若有）需要检查，看是否自由分区能合并于相邻的空闲分区；
              
        优势：- 避免分割大空闲块，当大部分分配是小尺寸时非常有效；
        
              - 最小化外部碎片产生的尺寸；
              
              - 比较简单；
    
        劣势：- 易产生外部碎片；
        
              - 重分配慢；
              
              - 易产生很多没用的微小碎片，不利于后续分配和管理；
              
     5、最差适配（worst fir）
     
        为了分配 n 字节，使用最大可用空闲块，以致块的尺寸比 n 大；
        
        需求：- 按尺寸排序的空闲块列表；
        
              - 分配很快（获得最大的分区）；
              
              - 重分配（若有）需要检查，看是否自由分区能合并于相邻的空闲分区；
              
         优势：避免有太多微小的碎片，分配中等尺寸效果最好；
         
         劣势：- 重分配慢；
         
               - 易产生外部碎片；
               
               - 易于破碎大的空闲块以致大分区无法被分配；
               
    小结：以上为简单管理算法，没有最好和最坏，因为程序需要的内存是随机的，可能大可能小。
     
## 连续物理内存分配：压缩式与交换式碎片整理

    压缩式compress：重置程序，合并空闲块（要求所有程序是动态可重置的）（何时重置？开销如何？）

    交换式swap：运行程序需要更多的内存时，抢占等待的程序，将等待程序copy到磁盘，回收他们的内存


# 第四章 操作系统对物理内存的管理（二）

## 非连续内存分配：分段（Segmentation）

一、使用非连续分配的原因

    1、连续内存分配的缺点：
    
        分配给一个程序的物理内存是连续的；
        
        内存利用率较低；
        
        有外碎片、内碎片的问题；
        
    2、非连续分配的优点：
    
        一个程序的物理地址空间是非连续的；
        
        更好的内存利用和管理；
        
        允许共享代码与数据（共享库等...）；
        
        支持动态加载和动态链接；
        
        缺点：管理开销大
        
        如何建立虚拟地址和物理地址之间的转换？可使用软件方案和硬件方案，软件方案开销可能很大，所以使用硬件
        
        两种硬件方案：分段、分页
        
二、分段 —— 更好地分离和共享

    进程的段地址空间由多个段组成：主代码段、子模块代码段、公用库代码段、堆栈段、堆数据、初始化数据段、符号表等

    将一个连续逻辑地址的应用程序（大的一维字节流，一段）  通过分段技术支持 映射为不连续的物理地址（多段）
        
三、分段寻址方案

    1、段访问机制
    
    - 一个段：一个内存块，一个逻辑地址空间
    
    - 程序访问内存地址需要：一个二维的二元组（s，addr；s —— 段号segnment；addr —— 段内偏移）

    - 有两种实现方式
    
        段寄存器 + 地址寄存器（s，addr分开存放，如x86）；
        
        单地址：（s，addr挨着存放）；
    
    2、段访问的硬件实现
    
![](https://i.bmp.ovh/imgs/2020/04/88b73b95ba7ae46a.png)

    （1）CPU执行应用程序的每条指令，通过段号寻找所在段的起始物理地址，映射关系在段表中储存；
    
            段表：由 OS （在寻址前）建立
            
                  - 存储段的起始地址（逻辑地址段号与物理地址段号的对应关系）；
            
                  - 存储段的长度限制；
                  
                  Index - 段号
                  
     （2）CPU通过段表信息，检查段长度是否满足长度限制，若满足，则合法，将起始地址+偏移量形成物理地址，取出数据交给CPU处理；
     
            若不满足，则为非法机制，CPU对OS产生异常。

    

## 非连续内存分配：分页（Paging）（大部分 CPU 采取的方式）

一、分页地址空间

    同样需要页号和页偏移；但段的大小可变，页帧/页大小不可变
    
    1、划分物理内存至固定大小的帧（frame）：大小是2的幂，eg：512,4096,8192；
    
        划分逻辑地址空间至相同大小的页（page）：大小是2的幂，eg：512,4096,8192
        
    2、建立方案：转换逻辑地址为物理地址（pages to frames）
    
        页表；
        
        MMU/TLB（快表，完成对页表的缓存）；
        
    3、帧：物理内存被分割为大小相等的帧
    
        一个内存物理地址是一个二元组（f，o）  物理地址 = 2^S X f + o
             
        f —— 帧号（F位，共有2^F个帧）  o —— 帧内偏移（S位，每帧有2^S字节）
        
        eg：16-bit的地址空间，9-bit（512 byte）大小的页帧，物理地址=（3,6），物理地址=1542
        
            F=7(16-9) S=9  f=3  o=6  物理地址 = 2^9*3+6 = 1536+6 = 1542
            
     4、页：一个程序的逻辑地址空间被划分为大小相等的页
     
        页内偏移的大小 = 帧内偏移的大小    页号大小 < / > 帧号大小
        
        一个逻辑地址是一个二元组（p,o）  虚拟地址 = 2^S X p + o
        
        p —— 页号（P位，2^P个页）  o —— 页内偏移（S位，每页有2^S字节）

二、页寻址机制 —— 页映射到帧

    1、程序的逻辑地址由很多页组成，每一页大小相同
    
        逻辑地址中的页号是连续的；物理地址中的帧号是不连续的；不是所有的页都有对应的帧
        
        页是连续的虚拟内存；帧是非连续的物理内存；有助于减少碎片
    
    2、实现过程
    
![](https://i.bmp.ovh/imgs/2020/04/258fe46dbe579727.png)
    
        （1）CPU 将页号作为索引，结合页表基址（PTBR - 页表基址寄存器），找到页表的存放位置，查询页表（一个大数组）
        
            若存在位为0，表示不存在此页号对应的帧号，异常；
            
            若存在位为1，表示存在，得到f（帧号）；
        
        （2）f 与 o 得到物理地址
        
        （OS 在之前建立页表）

## 非连续内存分配：页表（Page Table）

一、页表概述

    1、页表结构
    
        - 每个运行的程序都有一个页表，属于程序运行状态，会动态变化
        
        - 页表项组成：（1）帧号f
        
                     （2）页表项标志：存在位（resident bit）（硬件完成置 0 /1）；修改位（dirty bit）；引用位（clock/reference bit）
        
        eg：16位地址的系统（64KB，2^10^6）,32KB的物理内存，每页1024byte（偏移）
        
    2、分页机制的性能问题
    
        访问一个内存单元需要2次内存访问：一次用于获取页表项；一次用于访问数据
        
        （1）由于逻辑地址空间很大，导致页表可能非常大，eg：64位机器如果每页1024字节，一个页表的大小：2^64/2^10 = 2^54  
        
        （2）由于不同的应用程序需要不同的页表，n个则需要n份页表；
        
        （3）效率问题：CPU空间小，放不下页表，需将其放入内存，所以访问2次内存。
        
    3、如何解决？
    
        （1）缓存：常用数据或内容放入CPU中，提升访问速度；
        
        （2）间接访问
        

二、转换后备缓冲区（Translation Look-aside Buffer，TLB）—— 从速度上解决

    CPU 的 MMU 中
    
    缓存近期访问的页帧转换表项
    
    TLB使用associative memory（关联内存）实现，具备快速访问性能（速度快，时间代价大，所以容量小）；
    
    如果TLB命中，物理页号可以很快被获取；如果TLB未命中，则查页表，对应的表项被更新到TLB中。
    
    TLB未命中（缺失）的概率不会很大，一个32位系统有4K页表，访问4K次才会导致TLB缺失；写程序时尽量占用局部空间，减少缺失。
    
    TLB缺失后，从页表中取出再存到CPU中TLB的过程：-X86：由硬件完成；其它CPU：由os(软件)完成。

三、二级/多级 页表—— 从空间上解决（时间换空间）

    1、二级页表：将页号分为两个小的页号P1、P2，偏移地址不变，将对大页表的寻址分为对两个小页表的寻址
    
            CPU由P1及一级页表的起始地址查询一级页表，得到二级页表的起始地址；由P2及二级页表的起始地址得到帧号。
            
            优点：节省空间，若对应页号的表项不存在，则在二级页表中不需要存在
            
    2、多级页表：通过把页号分为k个部分，来实现多级间接页表，建立页表“树”

四、反向页表

    1、以上方法（前向映射）：页表大小与逻辑地址空间对应（以逻辑页页号作为index索引，来查找页号），逻辑地址空间越大，则页表越大
    
        反向映射：将物理地址的物理页号（页帧号）为索引，映射为逻辑地址的逻辑页号
        
                让页表与物理地址空间的大小相对应（逻辑/虚拟地址空间增长速度快于物理地址空间）
                
     2、基于页寄存器的方案
     
        （1）页寄存器中存放：帧号为索引，页号为值的数组
        
        （2）每个帧和一个寄存器关联，寄存器内容包括：存在位（residence bit）--此帧是否被占用、
        
            occupier--对应的页号P、保护位（protection bit）
            
            eg：物理内存大小 4096*4096=4K*4KB=16MB     页面大小4096bytes=4KB   页帧数4096=4K
            
                页寄存器使用的空间（假设8 bytes/register）8*4096=32 Kbytes
                
                页寄存器带来的额外开销32K/16M=0.2%（大约）———— 转换表的大小跟逻辑地址空间的大小无关
                
                虚拟内存的大小：任意
                
      3、基于关联内存的方案
      
        如果帧数较少，页寄存器可以被放置在关联内存中
        
        在关联内存中查找逻辑页号：成功--帧号被提取；失败--页错误异常（page fault）
        
        限制因素：大量的关联内存非常昂贵，难以在单个时钟周期内完成，耗电
        
      4、基于哈希（hash）查找的方案
      
        （1）在反向页表中通过哈希算法来搜索一个页对应的帧号
        
            对页号做哈希计算，为了在“帧表”（每帧拥有一个表项）中获取对应的帧号
            
            页i被放置在表中f（i）位置，其中f是设定的哈希函数
            
        （2）为了查找页i，执行下列操作：
        
            计算哈希函数f（i），并且使用它作为页寄存器表的索引；
            
            获取对应的页寄存器；
            
            检查寄存器标签是否包含i，如果包含，则代表成功，否则失败。
      
        （3）帧号和页号的对应关系由哈希函数实现（可硬件，可软件，为了速度快，用硬件）
        
            将哈希函数加上当前运行程序的ID，可提高查找速度

# 第五章  虚拟内存（一）

## 虚拟内存的起因

一、程序规模增长远快于存储器容量增长速度

    理想中的存储器：更大、更快、更便宜的非易失性存储器
    
    实际中的存储器：
    
![](https://i.bmp.ovh/imgs/2020/04/d7927a1c95a0e3b2.png)

    OS支持的存储器：更大、更快、更便宜好用的易失性存储器
    
二、在计算机系统中，尤其是在多道程序运行的环境下，可能会出现内存不够用的情况

    1、如果是是程序太大，超过了内存的容量，可以采用手动的覆盖（overlay）技术，只把需要的指令和数据保存在内存中；
    
    2、如果程序太多，超过了内存的容量，可采用自动交换（swapping）技术，把暂时不能执行的程序送到外存中；
    
    3、如果想要在有限容量的内存中，以更小的页粒度为单位装入更多更大的程序，可采用自动虚拟存储技术、
        
## 覆盖技术（产生于20世纪80年代、90年代初）

一、目标

    在较小的可用内存中运行较大的程序，常用于多道程序系统，与分区存储管理配合使用

二、原理

    依据程序自身逻辑结构，将程序划分为若干功能相对独立的模块；将不会同时执行的模块共享同一块内存区域，按时间先后运行（分时）。
    
    必要部分（常用功能）的代码和数据常驻内存；
    
    可选部分（不常用功能）放在其他程序模块中，平时存放在外存中，只在需要用到时装入内存；
    
    不存在调用关系的模块不必同时装入到内存，可相互覆盖，共用同一块内存区域。
    
![](https://i.bmp.ovh/imgs/2020/04/ef208b0ccd567bff.png)
    
    注：（1）调用时，放入覆盖区，B/C、D/E/F不会同时占用覆盖区
    
        （2）不会有相互调用关系的，可以放在一个覆盖区
        
三、缺点

    1、增加编程困难：
    
        需程序员划分功能模块，并确定模块间的覆盖关系，费时费力；
        
        增加了编程的复杂度；
        
    2、增加执行时间：
     
        从外存装入覆盖模块；
        
        时间换空间。
        
    eg：Turbo Pascal的Overlay系统单元支持程序员控制的覆盖技术

## 交换技术

一、目标

    多道程序在内存中时，增加正在运行或需要运行的程序的内存
    
二、实现方法

    （1）可将暂时不能运行的程序放到外存，从而获得空闲内存空间
    
    （2）OS把一个进程的整个地址空间的内容保存到外存中，而将外存中的某个进程的地址空间读入到内存中
    
        换入换出的基本单位/粒度：整个进程的地址空间
    
        换出（swap out）：把一个进程的整个地址空间保存到外存
    
        换入（swap in）：将外存中某进程的地址空间读入到内存
        
![](https://i.bmp.ovh/imgs/2020/04/44b4d83997625858.png)

三、面临的问题

    1、交换时机：何时需要发生交换？
    
        只当内存空间不够或有不够的可能时换出，尽量减少次数
    
    2、交换区大小
    
        必须足够大以存放所有用户进程的所有诶村映像的拷贝，必须能对这些内存映像进行直接存取
        
    3、程序换入时的重定位：换出后再换入时要放在原处吗？
    
        采用动态地址映射的方法

四、对程序员透明，由OS直接进行，程序员不需要知道具体细节

五、覆盖与交换的比较

    覆盖：--只能发生在没有调用关系的模块间（在一个程序里）；
    
          --程序员须给出模块间的逻辑覆盖结构；
          
          --发生在运行程序的内部模块间；
          
    交换：--以进程为单位；
    
          --不需要模块间的逻辑覆盖结构；
          
          --发生在内存程序之间（发生在内存中程序与管理程序/os之间）。
          
六、缺点

    粒度大，以进程作为交换的单位，需要把进程的整个地址空间都换进换出，增加了处理器的开销
  
## 虚存技术（虚拟内存管理技术）

一、目标

    1、只把部分程序放到内存中，从而运行比物理内存大的程序
    
        由操作系统自动完成，无需程序员的干涉；
    
    2、实现进程在内存与外存之间的交换，从而获得更多的空闲内存空间
    
        在内存和外存之间只交换进程的部分内容。

二、程序局部性原理（principle of locality）

    1、定义：程序在执行过程中的一个较短时期，所执行的指令地址和指令的操作数地址，分别局限于一定区域。
    
    2、时间局部性：一条指令的一次执行和下次执行，一个数据的一次访问和下次访问都集中在一个较短时期内
    
        空间局部性：当前指令和邻近的几条指令，当前访问的数据和邻近的几个数据都集中在一个较小区域内

        分支局部性：一条跳转指令的两次执行，很可能跳到相同的内存位置
        
    3、局部性原理的意义
    
        从理论上来说，虚拟存储技术是能够实现的，而且可取得满意的效果
        
![](https://i.bmp.ovh/imgs/2020/04/864640b99579e7b7.png)

![](https://i.bmp.ovh/imgs/2020/04/e58bc4319cb6738b.png)

    注：整型在32位系统中占4byte，4byte*1024=4K，OS每次取4K大小的数据，正好与一页容量相同

三、基本概念

    1、思路：将不常用的部分内存块暂存到外存
    
    2、原理（可在页式或段式内存管理的基础上实现）
    
        装载程序时：只将当前指令执行需要的部分页面或段装入内存
        
        指令执行中需要的指令或数据不在内存（称为缺页或缺段异常）时：处理器通知操作系统将相应的页面或段调入内存
        
        操作系统将内存中暂时不用的页面或段保存到外存，空出更多空闲空间存放将要装入的程序以及将要调入的页面或段
        
    3、实现方式：虚拟页式存储、虚拟段式存储

四、基本特征

    1、大用户空间：提供给用户的虚拟内存可大于实际的物理内存
    
        虚拟空间=物理空间+硬盘空间
        
    2、不连续性：物理内存分配非连续；虚拟地址空间使用非连续

    3、部分交换：虚拟存储只对部分虚拟地址空间进行调入和调出
    
五、虚拟存储的支持技术

    硬件：页式或短时存储中的地址转换机制
    
    操作系统：管理内存和外存间页面或段的换入和换出

六、虚拟页式内存管理

    1、在页式存储管理的基础上，增加请求调页和页面置换
    
    2、思路
    
        （1）当用户程序要装载到内存运行时，只装入部分页面，就启动程序运行；
        
        （2）进程在运行中发现有需要的代码或数据不在内存时，则向系统发出缺页异常请求；
        
        （3）操作系统在处理缺页异常时，将外存中相应的页面调入内存，使得进程能继续运行。
        
    3、页表表项
    
![](https://i.bmp.ovh/imgs/2020/04/042a749d6db9b42d.png)

        （1）驻留位：表示该页是否在内存
        
                1表示该页位于内存中，该页表项是有效的，可以使用；
                
                0表示该页当前在外存中，访问该页表项将导致缺页异常。
                
        （2）保护位：表示该页的允许访问方式，只读、可读写、可执行等。
        
        （3）修改位：表示在内存中的该页是否被修改过
        
            回收该物理页面时，据此判断是否要把它的内容写回外存
            
        （4）访问位：表示该页面是否被访问过（读或写），用于页面置换算法
        
    4、缺页中断
    
![](https://i.bmp.ovh/imgs/2020/04/707ce9ba9f8c114b.png)

    5、后备存储（Backing Store）
    
    （1）在何处保存未被映射的页？
    
        应能方便地找到在外存中的页面内容；
        
        交换空间（磁盘或者文件）：采用特殊格式存储未被映射的页面
        
    （2）虚拟页式存储中的外存选择————后备存储/二级存储
    
        一个虚拟地址空间的页面可以被映射到一个文件（在二级存储中）中的某个位置
    
        -- 代码段：映射到可执行二进制文件
        
        -- 动态加载的共享库程序段：映射到动态调用的库文件
        
        -- 其他段：可能被映射到交换文件（swap file）
        
    6、虚拟页式内存管理性能
    
        有效存储访问时间（effective memory access time EAT）= 访存时间 * (1-p) + 缺页异常处理时间 * 缺页率p
        
        eg：访存时间: 10 ns，磁盘访问时间: 5 ms，缺页率p，页修改概率q
        
            EAT = 10(1–p) + 5,000,000p(1+q) （1+q：可能换入或换出，时间也为5ms）
            
            若p足够小（程序局部性好），可使EAT接近于10ns
            
# 第六章  虚拟内存（二）

## 最优页面置换算法

一、置换算法

    1、功能：当出现缺页异常中断，需调入新页面而内存已满时，置换算法选择内存中被置换的物理页面
    
    2、目标：尽可能减少页面的调入调出次数（即缺页中断的次数），即把未来不再访问或短期内不访问的页面调出
    
            通常只能在局部性原理指导下依据过去的统计数据来进行预测
            
    3、页面锁定(frame locking)
    
        描述必须常驻内存的逻辑页面；操作系统的关键部分；要求响应速度的代码和数据；在置换时不置换该页面
        
        实现方法：在页表中添加锁定标志位(lock bit)
        
    4、评价方法：
    
        记录进程访问内存的页面轨迹；模拟页面置换行为，记录产生缺页的次数；更少的缺页, 更好的性能
        
    5、分类：
    
        （1）局部页面置换算法
        
            置换页面的选择范围仅限于当前进程占用的物理页面内；
            
            最优算法、先进先出算法、最近最久未使用算法；时钟算法、最不常用算法
            
        （2）全局页面置换算法
        
            置换页面的选择范围是所有可换出的物理页面；
            
            工作集算法、缺页率算法

二、最优页面置换算法

    1、基本思路：缺页时，计算内存中每个逻辑页面的下一次访问时间，置换在未来最长时间不访问的页面
        
        （在下一次访问之前需要等待时间最长的页面）
        
    2、算法特征
    
        （1）缺页最少，是理想情况；
        
        （2）实际系统中无法实现；
        
        （3）无法预知每个页面在下次访问前的等待时间；
        
        （4）可作为置换算法的性能评价依据（在模拟器上运行某个程序，并记录每一次的页面访问情况，第二遍运行时使用最优算法）
        
## 先进先出算法（First-In First-Out, FIFO）

一、思路

    选择在内存驻留时间最长的页面进行置换
    
二、实现

    维护一个记录所有位于内存中的逻辑页面链表；
    
    链表元素按驻留内存的时间排序，链首最长，链尾最短；

    出现缺页时，选择链首页面进行置换（链首淘汰出局），新页面加到链尾。
    
三、特征

    实现简单；
    
    性能较差，调出的页面可能是经常访问的；
    
    进程分配物理页面数增加时，缺页并不一定减少(Belady现象)；
    
    很少单独使用。
    
## 最近最久未使用算法(Least Recently Used, LRU)

一、思路

    缺页中断发生时，选择最长时间没有被引用的页面进行置换；
    
    如某些页面长时间未被访问，则它们在将来还可能会长时间不会访问；
    
    需要记录各个页面使用时间的先后顺序。

二、实现

    缺页时，计算内存中每个逻辑页面的上一次访问时间；
    
    选择上一次使用到当前时间最长的页面
    
三、特征

    最优置换算法（根据未来推测未来）的一种近似（根据历史推测未来）
    
    若程序局部性较好，则LRU能较好地预测未来
    
四、LRU算法的两种可能实现方法

    1、页面链表
    
        系统维护一个按最近一次访问时间排序的页面链表，链表首节点是最近刚刚使用过的页面，链表尾节点是最久未使用的页面；
        
        访问内存时，找到相应页面，并把它移到链表之首；缺页时，置换链表尾节点的页面。
        
    2、活动页面栈
    
        访问页面时，将此页号压入栈顶，并将栈内相同的页号抽出；缺页时，置换栈底的页面。
        
    3、两种实现方法特征：开销比较大
    
## 时钟页面置换算法（Clock）

一、思路

    仅对页面的访问情况进行大致统计，使用一个位进行近似

二、数据结构

    需要用到在页表项中访问位，描述页面在过去一段时间的内访问情况
    
    当一个页面被装入内存时，把该位初始化为0，若这个页面被访问（读/写），则把该位置1
    
    各页面组织成环形链表（类似为钟表面）；指针指向最先调入的页面
    
三、算法

    访问页面时，在页表项记录页面访问情况；缺页时，从指针处开始顺序查找未被访问的页面进行置换
    
    （访问位为0，立即淘汰；访问位为1，把该位置0，指针往下移动一格，循环，直到找到被淘汰的页面，然后把指针移动到它的下一格）

    （置1由硬件完成）

四、特征

    时钟算法是 LRU 和 FIFO 的折中，LRU 的近似，对 FIFO 的一种改进

五、实现

    页面装入内存时，访问位初始化为0；
    
    访问页面（读/写)时，访问位置1；
    
    缺页时，从指针当前位置顺序检查环形链表：访问位为0，则置换该页；
    
                                        访问位为1，则访问位置0，并指针移动到下一个页面，直到找到可置换的页面

## 二次机会法 / 改进的 Clock 算法

一、访问：可能为读，也可能为写

二、改进的Clock算法

    1、思路：减少修改页的缺页处理开销
    
    2、算法
    
        在页面中增加修改位（区分读/写），并在访问时进行相应修改（若修改过，则修改位置1，否则置0，由硬件完成）；
        
        缺页时，修改页面标志位，以跳过有修改的页面
        
        （写：内存中和硬盘中的内容不同，置换出去的时候，需要修改硬盘中相应的内容）
        
    3、存在位/修改位
    
        （1）0/0：淘汰，置换；
        
        （2）0/1：将修改位清零，指针移动到下一格；
        
        （3）1/0：存在位清零，指针移动到下一格；
        
        （4）1/1：存在位清零，修改位不变，指针移动到下一格
        
        将修改位为1的页有更多的机会留在内存中而不会被换走，则硬盘修改的次数减少；将只读的页优先换走

## 最不常用算法（Least Frequently Used, LFU）

一、思路

    缺页时，置换访问次数最少的页面，并淘汰

二、实现

    每个页面设置一个访问计数，访问页面时，访问计数加1；缺页时，置换计数最小的页面
    
三、特征

    算法开销大（需要一个计数器；且需要查找计数器中最小的数）；
    
    开始时频繁使用，但以后不使用的页面很难置换，解决方法：计数定期右移

四、LRU和LFU的区别

    LRU关注多久未访问，时间越短越好；LFU关注访问次数/频度，次数越多越好
    
## Belady 现象 、 LRU 、 FIFO 、 Clock 的比较

一、Belady（科学家的名字）现象

    1、现象：采用FIFO等算法时，可能出现分配的物理页面数增加，缺页次数反而升高的异常现象

    2、原因：FIFO算法（或类似算法）的置换特征与进程访问内存的动态特征矛盾
    
            （只表示存在的时间，不会记录访问的时间，谁存在的久，就置换谁，不管近期有没有被访问）；
    
            被它置换出去的页面并不一定是进程近期不会访问的
            
    3、FIFO有Belady现象；LRU没有
    
        原因：LRU满足暂算法现象，FIFO不满足

二、LRU、FIFO 和 Clock 的比较

    1、LRU 算法和 FIFO 本质上都是先进先出的思路
    
        LRU 依据页面的最近访问时间排序；LRU 需要动态地调整顺序；
        
        FIFO 依据页面进入内存的时间排序；FIFO 的页面进入时间是固定不变的（各页面之间的先后顺序是固定的）

    2、LRU可退化成FIFO

        如页面进入内存后没有被访问，最近访问时间与进入内存的时间相同
        
        例如：给进程分配3个物理页面，逻辑页面的访问顺序为1、2、3、4、5、6、1、2、3…
        
    3、LRU算法性能较好，但系统开销较大；FIFO算法系统开销较小，会发生Belady现象；
    
        Clock算法是它们的折衷：页面访问时，不动态调整页面在链表中的顺序，仅做标记；缺页时，再把它移动到链表末尾

    4、对于未被访问的页面，Clock和LRU算法的表现一样好；
    
        对于被访问过的页面，Clock算法不能记录准确访问顺序，而LRU算法可以

## 局部页替换算法的问题、工作集模型

一、局部置换算法问题

    分配的物理页帧数是固定的，没有考虑进程访存差异
    
二、全局置换算法

    1、思路：全局置换算法为进程分配可变数目的物理页面

    2、全局置换算法要解决的问题
    
        进程在不同阶段的内存需求是变化的；
        
        分配给进程的内存也需要在不同阶段有所变化；
        
        全局置换算法需要确定分配给进程的物理页面数。
        
三、工作集模型

    1、前面的各种页面置换算法，都基于程序的局部性原理
    
        若局部性原理不成立，则各种页面置换算法就没什么分别，也没有什么意义
        
        eg：假设进程对逻辑页面的访问顺序是1,2,3,4...单调递增，则在物理页面数有限时，不管采用何算法，每次访问必然导致页面中断
        
        若成立，如何证明它的存在，如何进行定量分析？此即工作集模型
        
    2、工作集
    
        一个进程当前正在使用的逻辑页面集合，可表示为二元函数W(t, )
        
        t是当前的执行时刻；
        
         称为工作集窗口（working-set window ），即一个定长的页面访问时间窗口；
        
        W(t, )是指在当前时刻 t 前的 时间窗口中的所有访问页面所组成的集合；
        
        | W(t, ) | 指工作集的大小，即页面数目，越小，则局部性越好
        
    3、工作集的大小变化
    
![](https://i.bmp.ovh/imgs/2020/04/fbac86f7ae504e84.png)

        进程开始执行后，随着访问新页面逐步建立较稳定的工作集；
        
        当内存访问的局部性区域的位置大致稳定时，工作集大小也大致稳定；
        
        局部性区域的位置改变时，工作集快速扩张和收缩过渡到下一个稳定值。
        
    4、常驻集
    
        （1）在当前时刻，进程实际驻留在内存当中的页面集合
        
        （2）工作集与常驻集的关系
        
            工作集是进程在运行过程中固有的性质；
            
            常驻集取决于系统分配给进程的物理页面数目和页面置换算法；
            
        （3）缺页率与常驻集的关系
        
            常驻集 包含（大于等于） 工作集时，缺页较少，进程将很顺利地运行，直到工作集发生剧烈变动，从而过渡到另一个状态；
            
            工作集发生剧烈变动（过渡）时，缺页较多；
            
            进程常驻集大小达到一定数目后，再给它分配更多的物理页面，缺页率也不会明显下降。
            
## 两个全局置换算法

一、工作集置换算法

    1、思路：换出不在工作集中的页面
    
    2、窗口大小τ：当前时刻前τ个内存访问的页引用是工作集，τ被称为窗口大小
    
    3、实现方法
    
        （1）访存链表：维护窗口内的访存页面链表；
        
        （2）访存时，换出不在工作集的页面；更新访存链表；
        
        （并不是不够才换出，而是不在工作集里面就换出）
        
        （3）缺页时，换入页面；更新访存链表。
        
        （换入和换出不同时执行，有换入就不会换出）
        
二、缺页率置换算法（PFF, Page-Fault-Frequency）

    1、可变分配策略：常驻集大小可变，在进程运行过程中动态地调整常驻集大小
    
        可采用全局页面置换方式，当发生一个缺页中断时，被置换的页面可在其他进程中，各个并发进程竞争地使用物理页面
        
        优缺点：性能较好，但增加了系统开销
        
        具体实现：可使用缺页率算法来动态调整常驻集大小

    2、缺页率(page fault rate)

        （1）定义：缺页次数 / 内存访问次数 或 缺页平均时间间隔的倒数；
        
        （2）影响缺页率的因素

            页面置换算法；分配给进程的物理页面数目；页面本身大小；程序的编写方法（局部性的好坏）
            
    3、缺页率置换算法
    
        通过调节常驻集大小，使每个进程的缺页率保持在一个合理的范围内；
        
        若进程缺页率过高，则增加常驻集以分配更多的物理页面；若进程缺页率过低，则减少常驻集以减少它的物理页面数。
        
    4、缺页率置换算法的实现
    
        -- 访存时，设置引用位标志；
        
        -- 缺页时，计算从上次缺页时间tlast 到现在tcurrent 的时间间隔：
        
            如果 tcurrent – tlast>T（阈值时间），则置换所有在[tlast ,  tcurrent ]时间内没有被引用的页；
            
            如果tcurrent – tlast ≤ T，则增加缺失页到工作集中
            
## 抖动问题(thrashing)

一、抖动

    进程物理页面太少，不能包含整个的工作集，即常驻集<工作集；
    
    造成大量缺页中断，需频繁在内存与外存之间替换页面，使进程运行速度变慢。
    
二、产生抖动的原因

    随着驻留内存的进程数目增加，分配给每个进程的物理页面数不断减小，缺页率不断上升；
    
    操作系统需选择一个适当的进程数目和进程需要的物理页面数，在并发水平和缺页率之间达到一个平衡
    
三、抖动问题可能会被本地的页面置换改善

    更好的规则为负载控制：通过调节并发进程数（MPL）来进行系统负载控制
    
![](https://i.bmp.ovh/imgs/2020/04/156f90fa8a9f9c31.png)

    N-I/O-BALANCE 为平衡点，跑的进程多，抖动现象也少，对硬件资源充分利用

    （求和）WSi  = 内存的大小；平均缺页间隔时间(MTBF) = 缺页异常处理时间(PFST)
    
    MPL-multiprogramming level；MTBF-mean time between page faults；PFST-page fault service time
    

# 第七章   进程管理

## 进程（Process）描述

一、进程定义

    进程是指一个具有一定独立功能的程序在一个数据集合上的一次动态执行过程（动态的！！）

![](https://i.bmp.ovh/imgs/2020/04/c15353bd8f04563e.png)

二、进程的组成

    1、进程包含了正在运行的一个程序的所有状态信息。
    
        代码；数据；程序计数器中的值，指示下一条将运行的指令；状态寄存器（CPU状态CR0、指令指针IP，堆、栈）；
    
        通用寄存器（AX、BX、CX…）；进程占用系统资源（打开文件、已分配内存…） 
    
    2、进程与程序的联系
    
        （1）程序是产生进程的基础，进程是操作系统处于执行状态程序的抽象，是程序功能的体现
        
            程序 = 文件 (静态！！的可执行文件)；进程 = 执行中的程序 = 程序 + 执行状态
            
        （2）程序的每次运行构成不同的进程，同一个程序的多次执行过程对应为不同进程：如命令“ls”的多次执行对应多个进程
        
            通过多次执行，一个程序可对应多个进程；通过调用关系，一个进程可包括多个程序
            
            （多对多的映射关系）
            
        （3）进程执行需要的资源
        
            内存：保存代码和数据；CPU：执行指令
            
     3、进程与程序的区别
        
        （1）进程是动态的，程序是静态的
        
            程序是有序代码的集合；进程是程序的执行，进程有核心态/用户态（进程中有些功能需要OS执行，此时，OS代表进程处于核心态）
            
        （2）进程是暂时的，程序的永久的
        
            进程是一个状态变化的过程；程序可长久保存
            
        （3）进程与程序的组成不同
        
            进程的组成包括程序、数据和进程控制块（即进程状态信息）
            
        eg：食谱=程序；人=CPU；原料=数据；做饭=进程 

三、进程的特点

    1、动态性：可动态地创建、结束进程

    2、并发性：进程可以被独立调度并占用处理机运行

    3、独立性：不同进程的工作不相互影响

    4、制约性：因访问共享数据/资源或进程间同步而产生制约

四、进程控制结构

    1、进程控制块（PCB，Process Control Block）：操作系统管理控制进程运行所用的信息集合
    
        操作系统用PCB来描述进程的基本情况以及运行变化的过程（描述进程的数据结构）；
        
        （程序=算法+数据结构）
        
        PCB是进程存在的唯一标志：每个进程都在操作系统中有一个对应的PCB（PCB与进程一对一）
        
    2、进程控制块的使用
    
        进程创建：生成该进程的PCB；
        
        进程终止：回收它的PCB；
        
        进程的组织管理：通过对PCB的组织管理来实现
        
    3、PCB包含三大类信息
    
        （1）进程标识信息：如本进程的标识（如ID），本进程的产生者标识（父进程标识）；用户标识
        
        （2）处理机状态信息保存区：保存进程的运行现场信息
        
            -- 用户可见寄存器：用户可以使用的数据，地址等寄存器；
            
            -- 控制和状态寄存器：如程序计数器（PC），程序状态字（PSW）
            
            -- 栈指针：过程调用/系统调用/中断处理和返回时需要用到它
            
         （3）进程控制信息
         
            -- 调度和状态信息：用于OS调度进程和处理机使用情况
            
            -- 进程间通信信息：进程间通信相关的各种标识、信号、信件等，这些信息存在接收方的进程控制块中
            
            -- 存储管理信息：指向进程映像存储空间数据结构
            
            -- 进程所用资源：进程使用的系统资源，如打开文件等
            
            -- 有关数据结构连接信息：进程可以连接到一个进程队列中，或连接到相关的其他进程的PCB
            
    4、PCB的组织方式
    
        （1）链表：同一状态的进程其PCB成一链表，多个状态对应多个不同的链表
        
            各状态的进程形成不同的链表：就绪链表、阻塞链表
            
            （需要动态插入删除，用链表开销小）
            
        （2）索引表：同一状态的进程归入一个索引表（由索引指向PCB），多个状态对应多个不同的索引表
        
            各状态的进程形成不同的索引表：就绪索引表、阻塞索引表
        
## 进程状态

一、进程的生命期管理

    1、进程的生命周期划分
    
        进程创建、进程执行、进程等待、进程抢占、进程唤醒、进程结束
        
    2、进程创建（创建———就绪）
    
        引起进程创建的情况：系统初始化时；用户请求创建一个新进程；正在运行的进程执行了创建进程的系统调用
        
    3、进程执行（就绪——运行）
    
        内核选择（调度算法）一个就绪（可执行）的进程，让它占用处理机并执行
    
    4、进程等待（由进程自身发起）（运行——等待）
    
        进程进入等待(阻塞)的情况：-- 请求并等待系统服务，无法马上完成；
        
                                -- 启动某种操作，无法马上完成；
                                
                                -- 需要的数据没有到达
                                
        进程只有自己阻塞自己，因为只有进程自身才能知道何时需要等待某种事件的发生
        
    5、进程抢占（运行——就绪）
    
        进程会被抢占的情况：高优先级进程就绪；进程执行当前时间用完
        
    6、进程唤醒（等待——就绪）
    
        唤醒进程的情况：被阻塞进程需要的资源可被满足；被阻塞进程等待的事件到达；将该进程的PCB插入到就绪队列

        进程只能被别的进程或操作系统唤醒
        
    7、进程结束（运行——退出）
    
        进程结束的情况：正常退出(自愿的)；错误退出(自愿的)；致命错误(强制性的)；被其他进程所杀(强制性的)
    
二、进程状态变化模型

![](https://i.bmp.ovh/imgs/2020/04/6f64096aa474c162.png)

    1、进程的三种基本状态：进程在生命结束前处于且仅处于三种基本状态之一
    
        不同系统摄者的进程状态数目不同
        
        运行状态：当一个进程正在处理机上运行时；
        
        就绪状态：一个进程获得了除处理机之外的一切所需资源，一旦得到处理机即可运行；
        
        等待状态/阻塞状态（bolcked）：一个进程正在等待某一时间而暂停运行，如等待某资源、输入/输出完成。
        
    2、可能的状态变化：
    
    （1）NULL→创建：一个新进程被产生出来执行一个程序；
    
    （2）创建→就绪：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态；（该过程很快）
    
    （3）就绪→运行：处于就绪状态的进程被进程调度程序选中后，就分配到处理机上来运行；
    
    （4）运行→结束：当进程表示它已经完成或者因出错，当前运行进程会由操作系统作结束处理；
    
    （5）运行→就绪：处于运行状态的进程在其运行过程中，由于分配给它的处理机时间片用完而让出处理机（OS执行）；
    
    （6）运行→等待：当进程请求某资源且必须等待时；
    
    （7）等待→就绪：当进程要等待某事件到来时，它从阻塞状态变到就绪状态（OS完成）。

三、进程挂起模型

![](https://i.bmp.ovh/imgs/2020/04/855cef34622d6ceb.png)

    1、进程挂起：处在挂起状态的进程映像在磁盘上，没有占用内存空间，目的是减少进程占用内存
    
    2、挂起状态
    
    （1）等待/阻塞挂起状态（Blocked-suspend）：进程在外存并等待某事件的出现
    
    （2）就绪挂起状态（Ready-suspend）：进程在外存，但只要进入内存，即可运行
    
    3、与挂起相关的状态转换
    
    （1）挂起(Suspend)：把一个进程从内存转到外存，可能有以下几种情况：
    
        等待到等待挂起：没有进程处于就绪状态或就绪进程要求更多内存资源，以提交新进程或运行就绪进程
        
        就绪到就绪挂起：当有高优先级等待（系统认为会很快就绪的）进程和低优先级就绪进程，系统选择挂起低优先级就绪进程

        运行到就绪挂起：对抢先式分时系统，当有高优先级等待挂起进程因事件出现而进入就绪挂起
        
    （2）在外存时的状态转换
    
        等待挂起到就绪挂起：当有等待挂起进程因相关事件出现（此时所有数据等仍然存在外存上）
        
    （3）激活/解挂（Activate）：把一个进程从外存转到内存
    
        就绪挂起到就绪：没有就绪进程或挂起就绪进程优先级高于就绪进程
        
        等待挂起到等待：当一个进程释放足够内存，并有高优先级等待挂起进程

四、状态队列

    由操作系统来维护一组队列，表示系统中所有进程的当前状态
    
    不同队列表示不同状态：就绪队列、各种等待队列
    
    根据进程状态不同，进程PCB加入相应队列：进程状态变化时，它所在的PCB会从一个队列换到另一个
    
## 线程（Thread）

一、产生线程的原因：

    在进程内部增加一类实体，满足以下特性：
    
        （1）实体之间可以并发执行；（2）实体之间共享相同的地址空间；
        
        这种实体就是线程（Thread）

二、线程

    1、线程是进程的一部分，描述指令流执行状态。它是进程中的指令执行流的最小单元，是CPU调度的基本单位。
    
    2、进程的资源分配角色：进程由一组相关资源构成，包括地址空间（代码段、数据段）、打开的文件等各种资源。
    
    3、线程的处理机调度角色：线程描述在进程资源环境中的指令流执行状态。

三、线程 = 进程 - 共享资源

    1、线程的优点：
    
        一个进程中可以同时存在多个线程；
        
        各个线程之间可以并发地执行；
        
        各个线程之间可以共享地址空间和文件等资源。
        
    2、线程的缺点：一个线程崩溃，会导致其所属进程的所有线程崩溃

四、不同操作系统对线程的支持

    单进程系统：MS-DOS；单进程多线程系统：pSOS；多进程系统：传统UNIX；多线程系统：现代UNIX、Windows、Linux
    
五、线程与进程的比较

    1、进程是资源（内存、文件、网页等）分配单位，线程是CPU调度单位
    
    2、进程拥有一个完整的资源平台，而线程只独享指令流执行的必要资源，如寄存器和栈
    
    3、线程具有就绪、等待和运行三种基本状态和状态间的转换关系
    
    4、线程能减少并发执行的时间和空间开销
    
        线程的创建时间比进程短（进程创建时还需要创建内存怎么管理等，线程创建时其所属的进程已经创建好了这些问题）；
        
        线程的终止时间比进程短（线程不需要考虑内存等释放问题）；
        
        同一进程内的线程（具有同一个页表，所有信息可以重用）切换时间比进程（需要切换页表）短；
        
        由于同一进程的各线程间共享内存和文件资源，可不通过内核进行直接通信。
        
六、线程的实现

    1、线程的三种实现方式
    
    （1）用户线程（OS看不到的线程，由用户线程库完成管理）：在用户空间实现，POSIX Pthreads，Mach C-threads，Solaris threads
    
    （2）内核线程（OS管理的线程）：在内核中实现，Windows，Solaris，Linux
    
    （3）轻量级进程(LightWeight Process)：在内核中实现，支持用户线程，Solaris
    
    2、用户线程与内核线程的对应关系：多对一；一对一；多对多
    
七、用户线程
    
    1、用户线程：由一组用户级的线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等
    
    2、用户线程的特征
    
    （1）不依赖于操作系统的内核
    
        内核不了解用户线程的存在；可用于不支持线程的多进程操作系统
        
    （2）在用户空间实现的线程机制
    
        每个进程有私有的线程控制块（TCB）列表，用来跟踪记录它的各个线程状态信息（PC，栈指针，寄存器）；
        
        TCB由线程库函数维护
        
    （3）同一进程内的用户线程切换速度快：由线程库函数完成，无需用户态/核心态切换
    
    （4）允许每个进程拥有自已的线程调度算法
    
    3、用户线程的不足
    
    （1）线程发起系统调用而阻塞时，则整个进程进入等待
    
    （2）不支持基于线程的处理机抢占：除非当前运行线程主动放弃，它所在进程的其他线程无法抢占CPU
    
    （用户态进程没有权利打断当前线程，但是OS有，因为有中断）
    
    （3）只能按进程分配CPU时间：多个线程进程中，每个线程的时间片较少，执行较慢
    
八、内核线程

    1、由内核通过系统调用实现的线程机制，由内核完成线程的创建、终止和管理
    
    2、内核线程的特征
    
    （1）由内核维护PCB和TCB（进程和线程的上下文信息）；
    
    （2）线程执行系统调用而被阻塞不影响其他线程
    
    （3）线程的创建、终止和切换开销相对较大：通过系统调用/内核函数，在内核实现
    
    （4）以线程为单位进行CPU时间分配：多线程的进程可获得更多CPU时间
    
九、轻权进程(LightWeight Process)/轻量级进程

    内核支持的用户线程
    
    一个进程可有一个或多个轻量级进程，每个轻权进程由一个单独的内核线程来支持。（Solaris/Linux）
    
## 上下文切换/进程切换

一、进程切换(上下文切换)

    暂停当前运行进程，从运行状态变成其他状态；并调度另一个进程从就绪状态变成运行状态
    
二、进程切换的要求

    切换前，保存进程上下文；切换后，恢复进程上下文，进程不能显示它曾经被暂停过；快速切换
    
三、需要存储进程生命周期的信息

    寄存器 (PC, SP, …)；CPU状态；内存地址空间
    
    （实际实现希望开销越小越好，用汇编语言实现）
    
四、进程控制块PCB:内核的进程状态记录

    内核为每个进程维护了对应的进程控制块（PCB)；
    
    内核将相同状态的进程的PCB放置在同一队列：就绪队列；I/O等待队列（每个设备一个队列）；僵尸队列

## 进程控制

一、创建进程

    1、Windows进程创建API： CreateProcess(filename)

        创建时关闭所有在子进程里的文件描述符 CreateProcess(filename, CLOSE_FD)；
        
        创建时改变子进程的环境 CreateProcess(filename, CLOSE_FD, new_envp)；
        
        等等
        
    2、Unix进程创建系统调用： fork/exec
    
        --fork()把一个进程复制成二个进程：parent (old PID), child (new PID)；
        
          exec()用新程序来重写当前进程：PID没有改变。

        --用fork和exec创建进程的示例：
        
            int pid = fork()；		// 创建子进程

            if(pid == 0) {			// 子进程在这里继续
            // Do anything (unmap memory, close net connections…)
	        exec(“program”, argc, argv0, argv1, …);
            } 
            
         -- fork() 创建一个继承的子进程
         
            复制父进程的所有变量和内存；
            
            复制父进程的所有CPU寄存器(有一个寄存器例外)。
            
         -- fork()的返回值
         
             子进程的fork()返回0；父进程的fork()返回子进程标识符；
             
             fork() 返回值可方便后续使用，子进程可使用getpid()获取PID
             
         -- fork()的地址空间复制
         
            fork()执行过程对于子进程而言，是在调用时间对父进程地址空间的一次复制

二、加载和执行进程

    1、系统调用exec( )加载新程序取代当前运行进程
    
        exec()示例代码
       
       ``` 
        main()
        …
        int pid = fork();			// 创建子进程
        if (pid == 0) {			// 子进程在这里继续
            exec_status = exec(“calc”, argc, argv0, argv1, …);
            printf(“Why would I execute?”);
        }  else {				// 父进程在这里继续
            printf(“Whose your daddy?”);
            …
            child_status = wait(pid);
        }
        ```











    



    
    
    
## 进程间通信


## 进程互斥与同步


## 死锁（Deadlock）


    


        
        


























        
        






        
        
        
        







    
    

        
        


      
        
    
        



        
        
    
    


    

        

           
           
       

   


